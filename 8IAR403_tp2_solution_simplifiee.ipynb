{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "Solution duTravail pratique #2<br>\n",
    "\n",
    "## Entraînement et mesure de performance d’apprentissage<br>\n",
    "<div align=\"center\">\n",
    "Dans le cadre du cours 8IAR403 – apprentissage automatique pour la science des données<br><br>\n",
    "Le 10 mars 2025<br><br>\n",
    "</div></div>\n",
    "\n",
    "***\n",
    "\n",
    "L'ensemble de données exploré dans ce second travail pratique est issu d'un site de commerce électronique, représentant les revenus\n",
    "générés par les clients.\n",
    "\n",
    "Cette analyse vise à explorer les étapes et paramétrage d'un modèle d'entraînement,  et de mesure de performances d'un modèle, en exploitant\n",
    "deux types de classeurs:\n",
    "\n",
    "* Un classeur binaire appliqué à un ensemble de données possédant deux classes.\n",
    "* Un classeur multi-classe appliqué à un ensemble de données possédant trois classes.\n",
    "\n",
    "Ces deux évaluations permettront de comparer la performance de chacun des classeurs et d'identifier le modèle et les\n",
    "hyper-paramètres les plus appropiés, ie. moins de surajustement.\n",
    "\n",
    "_Il est à noter que cette analyse complète celle produite lors du travail pratique #1. Ainsi, nous réutiliserons\n",
    "les mêmes approche de nettoyage et préparation des données, appliqués sous forme de pipelines de transformation permettant de générer notre TBA._ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initialisation et déclaration des fonctions<a name=\"initialisation\"></a>\n",
    "Cette première section permet l'initialisation des paramètres essentiels au bon fonctionnement du projet et\n",
    "définit les différentes fonctions utilisées dans le cadre de celui-ci.\n",
    "\n",
    "### Importation des bibliothèques pour l'exécution d'un projet d'apprentissage machine\n",
    "\n",
    "Nous débutons par l'importation des bibliothèques nécessaires pour ce projet d'apprentissage machine.\n",
    "Les bibliothèques utilisées sont:\n",
    "1. __pandas__, permettant l'importation et la gestion des ensembles de données nécessaires au projet.\n",
    "2. __numpy__, permettant les manipulations, évaluations et fonctions mathématiques avancées sur les données.\n",
    "3. __os__, permettant la gestion d'emplacement des fichiers.\n",
    "4. __matplotlyb__, pour les éléments de visualisation.\n",
    "5. __sklearn__, pour plusieurs opérations de traitement, mises à l'échelle et de transformation dans un contexte de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.compose import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, recall_score, precision_score, f1_score, make_scorer, roc_curve, auc, accuracy_score\n",
    "from sklearn import metrics\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres utilisateurs\n",
    "\n",
    "Cette section vise à initialiser les paramètres utilisateurs. Plus précisément, dans le cadre de ce travail pratique,\n",
    "ces paramètres correspondent aux noms et emplacements des fichiers de données, ainsi qu'aux ratios de division des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Emplacement des fichiers\n",
    "filepath_dataset = \"Datasets\"\n",
    "\n",
    "#Noms des fichiers\n",
    "filename_customer = \"Customer.csv\"\n",
    "filename_country_pop = \"CountryPopulation.csv\"\n",
    "filename_country_gdp = \"CountryGDP.csv\"\n",
    "\n",
    "# Ratio des données de test par rapport aux données d'entrainement\n",
    "test_train_ratio = 0.2\n",
    "\n",
    "# Seed permettant de reproduire la distribution aléatoire\n",
    "random_state_seed = 42\n",
    "\n",
    "# Inclusion ou non du POP et GDP dans le merge\n",
    "\n",
    "sans_merge = False\n",
    "merge_gdp = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Préparation de la TBA<a name=\"preparation\"></a>\n",
    "\n",
    "La présente analyse complète celle produite lors du travail pratique #1. Ainsi, nous réutiliserons\n",
    "les mêmes approches de nettoyage et préparation des données, appliqués sous forme de pipelines de transformation permettant\n",
    "de générer notre TBA. Afin d'accélérer l'exécution, cette étape de préparation de la TBA détaille chacune des fonctions\n",
    "uniquement sous forme de commentaires dans le code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### Fonction de bornage des données aberrantes (outliers)\n",
    "def nettoyageOutliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = df.columns\n",
    "\n",
    "    #Calcul de l'écart interquartile\n",
    "    Q25 = df[cols].quantile(0.25)  #Q1 on définit le premier quartile pour c\n",
    "    Q75 = df[cols].quantile(0.75)\n",
    "    IQR = Q75 - Q25\n",
    "\n",
    "    #Calcul des bornages inférieurs et supérieurs à l'IQR\n",
    "    SeuilMin = (Q25 - 1.5 * IQR)\n",
    "    SeuilMax = (Q75 + 1.5 * IQR)\n",
    "\n",
    "    # Remplacer les outliers à l'extérieur des bornes IQR par les valeurs correspondantes\n",
    "    nouv_df = df[cols].clip(SeuilMin[cols], SeuilMax[cols], axis=1)\n",
    "    return nouv_df\n",
    "\n",
    "def bornage(data):\n",
    "    return nettoyageOutliers(pd.DataFrame(data))\n",
    "\n",
    "#### Fonction de concaténation (merge) des ensembles de données\n",
    "def mergeDataset(data: pd.DataFrame, pop=False, pib=False):\n",
    "\n",
    "    if pop == True:\n",
    "        #aucune jointure\n",
    "        return data\n",
    "    \n",
    "    data_enrichie = pd.merge(data, data_pays)\n",
    "\n",
    "    if pib == True:\n",
    "        #jointure entre le data et le data_pib\n",
    "        data_enrichie = data_enrichie.merge(data_pib)\n",
    "    return data_enrichie\n",
    "\n",
    "#### Fonction de conversion de caractéristiques au format numérique\n",
    "def toNum(data: pd.DataFrame):\n",
    "    data['first_item_prize'] = pd.to_numeric(data['first_item_prize'])\n",
    "    return data\n",
    "\n",
    "### Pipeline de traitement des données numériques\n",
    "num_transformer = Pipeline([\n",
    "    ('toNum', FunctionTransformer(toNum, validate=False)),\n",
    "    # Nettoyage par remplacement de valeurs manquantes\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    # Remplacement des données aberrantes\n",
    "    ('clamp', FunctionTransformer(bornage, validate=False))\n",
    "])\n",
    "\n",
    "### Pipeline de traitement des données catégorielles\n",
    "cat_transformer = Pipeline([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "### Pipeline de tranformation des données numériques et catégorielles\n",
    "preparationData = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, make_column_selector(dtype_include=np.number)),\n",
    "        ('cat', cat_transformer, make_column_selector(dtype_exclude=np.number))\n",
    "    ]\n",
    ")\n",
    "\n",
    "### Pipeline complet\n",
    "full_pipeline = Pipeline([\n",
    "    ('merge', FunctionTransformer(mergeDataset, kw_args={\"pop\":sans_merge, \"pib\": merge_gdp}, validate=False)),\n",
    "    ('preparation', preparationData),\n",
    "    ('standard_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Chargement des ensembles de données\n",
    "Chargement des trois ensembles de données (Customer, Population et PIB) en spécifiant le format des données manquantes et\n",
    "en s'assurant de faire correspondre le nom des colonnes pour les opérations de concaténation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importation du fichier de données customer\n",
    "data_client = pd.read_csv(os.path.join(filepath_dataset, filename_customer), na_values=['?', 'unknown'])\n",
    "\n",
    "# Importation du fichier de données Population par pays et modification du nom de colonne \"Country\"\n",
    "data_pays = pd.read_csv(os.path.join(filepath_dataset, filename_country_pop), na_values=['?', 'unknown'])\n",
    "data_pays.columns = ['country', 'population']\n",
    "\n",
    "# Importation du fichier de données PIB et modificationd de la colonne \"Country\"\n",
    "data_pib = pd.read_csv(os.path.join(filepath_dataset, filename_country_gdp), na_values=['?', 'unknown'])\n",
    "data_pib.columns = ['country', 'GDP_inhab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Séparation de données d'entraînement et d'évaluation\n",
    "\n",
    "Afin d'éviter d'introduire des biais dans l'évaluation de nos données, le jeu de données est immédiatement scindé en\n",
    "données d'entraînement et données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble de données original:\n",
      " (10000, 8)\n",
      "Taille de l'ensemble de données d'entraînement:\n",
      " (8000, 8)\n",
      "Taille de l'ensemble de données d'évaluation:\n",
      " (2000, 8)\n"
     ]
    }
   ],
   "source": [
    "# division des ensemble de données.\n",
    "train_set, test_set = train_test_split(data_client, test_size=test_train_ratio, random_state=random_state_seed)\n",
    "\n",
    "# Validation de la taille des ensembles de données d'entrainement et de test\n",
    "print(\"Taille de l'ensemble de données original:\\n\", data_client.shape)\n",
    "print(\"Taille de l'ensemble de données d'entraînement:\\n\", train_set.shape)\n",
    "print(\"Taille de l'ensemble de données d'évaluation:\\n\", test_set.shape)\n",
    "\n",
    "# Comme la variable revenue est retirée du jeu de données avant d'exécuter le pipeline, les NaN sont remplacés directement\n",
    "train_set[\"revenue\"].replace(np.nan, train_set[\"revenue\"].median(), inplace=True)\n",
    "test_set[\"revenue\"].replace(np.nan, test_set[\"revenue\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Question 2.1 - Entraînement d’un classeur binaire<a name=\"classbinaire\"></a>\n",
    "\n",
    "Dans un premier temps, on souhaite créer un classeur binaire dont la variable cible est le revenu. Il s’agit de prédire\n",
    "si un client est susceptible ou non de générer plus de revenus que la moyenne.\n",
    "\n",
    "\n",
    "## Question 2.1.1 - Transformation binaire de la variable \"_revenue_\"<a name=\"binarisation\"></a>\n",
    "\n",
    "Fonction permettant de remplacer la valeur de la variable \"_revenue_\" par rapport à la moyenne:\n",
    "* Valeur 1: _Revenue_ supérieur à la moyenne\n",
    "* Valeur 0: _Revenue_ inférieur ou égal à la moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution du revenue en fonction de la moyenne:\n",
      "0: Plus petit ou égal, 1: Plus grand que la moyenne\n",
      "revenue\n",
      "0    4865\n",
      "1    3135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def binarize_att (data: pd.DataFrame, att_name):\n",
    "\n",
    "    att_mean = data[att_name].mean()\n",
    "    # 1 si supérieur à la moyenne, 0 si inférieur\n",
    "    #data[att_name] = (data[att_name] > att_mean).astype(int)\n",
    "    data[att_name] = np.where(data[att_name] > att_mean, 1, 0)\n",
    "    return data\n",
    "\n",
    "# Transformation de l'attribut revenue en classe binaire pour les ensembles d'entrainement et de test\n",
    "train_set_bin = binarize_att(train_set.copy(), \"revenue\")\n",
    "test_set_bin = binarize_att(test_set.copy(), \"revenue\")\n",
    "\n",
    "print(\"Distribution du revenue en fonction de la moyenne:\")\n",
    "print(\"0: Plus petit ou égal, 1: Plus grand que la moyenne\")\n",
    "print(train_set_bin[\"revenue\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Retrait de l'attribut de classification \"_revenue_\"\n",
    "\n",
    "Afin d'exploiter l'arbre binaire de classification, l'attribut de classification \"_revenue_\" est retirée de l'ensemble\n",
    "de données, le but étant de mesurer avec quelle précision le modèle pourra la prédire.\n",
    "\n",
    "Les valeurs de l'attribut sont toutefois stockées dans les variables _Y\\_train_ et _Y\\_test_ afin d'évaluer la précision du modèle dans une étape subséquente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Retrait de la variable revenue de l'ensemble d'entrainement\n",
    "X_train = train_set_bin.drop(['revenue'], axis=1)\n",
    "Y_train = train_set_bin['revenue']\n",
    "\n",
    "### Retrait de la variable revenue de l'ensemble de test\n",
    "X_test = test_set_bin.drop(['revenue'],axis =1)\n",
    "Y_test = test_set_bin['revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Application des pipelines\n",
    "\n",
    "Les données préparées et l'attribut de classification retiré, les données sont transformés par l'application des\n",
    "différents pipelines configurés à l'étape [Préparation de la TBA](#preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#considerer uniquement le dataset Customer. Scénario1\n",
    "sans_merge = True\n",
    "X_train_nopop = full_pipeline.fit_transform(X_train)\n",
    "X_test_nopop = full_pipeline.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline appliqué aux données, sans le PIB. Scenario 2\n",
    "merge_gdp = False\n",
    "X_train_nogdp = full_pipeline.fit_transform(X_train)\n",
    "X_test_nogdp = full_pipeline.fit_transform(X_test)\n",
    "\n",
    "\n",
    "# Pipeline appliqué aux données, avec le PIB. Scenario 3\n",
    "merge_gdp = True\n",
    "X_train_gdp = full_pipeline.fit_transform(X_train)\n",
    "X_test_gdp = full_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2.1.2 - Échantillonnage aléatoire stratifié<a name=\"sampling\"></a>\n",
    "\n",
    "Nous procédons donc à l'échantillonnage aléatoire stratifié de nos ensembles de données selon des échantillons de taille 2000, 4000 et 8000.\n",
    "\n",
    "Chacun des échantillons est généré afin d'inclure ou non le PIB, en fonction de la valeur de la variable _merge\\_gdp_ passée au _pipeline_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Dictionnaire des tailles d'échantillonnage aléatoire. Seul les trois premières valeurs sont retenues.\n",
    "sample_size = [2000, 4000, 8000]\n",
    "\n",
    "sans_merge = True\n",
    "#Création des jeux d'entrainement (X_train) et de validation (Y_train) pour le scénario 1\n",
    "X_train_nopop_samp1, Y_train_nopop_samp1 = resample(X_train_nopop, Y_train, n_samples=sample_size[0], random_state=random_state_seed, stratify=Y_train)\n",
    "X_train_nopop_samp2, Y_train_nopop_samp2 = resample(X_train_nopop, Y_train, n_samples=sample_size[1], random_state=random_state_seed, stratify=Y_train)\n",
    "X_train_nopop_samp3, Y_train_nopop_samp3 = resample(X_train_nopop, Y_train, n_samples=sample_size[2], random_state=random_state_seed, stratify=Y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Création des jeux d'entrainement (X_train) et de validation (Y_train) sans PIB : scenario 2\n",
    "\n",
    "merge_gdp = False\n",
    "X_train_nogdp_samp1, Y_train_nogdp_samp1 = resample(X_train_nogdp, Y_train, n_samples=sample_size[0], random_state=random_state_seed, stratify=Y_train)\n",
    "X_train_nogdp_samp2, Y_train_nogdp_samp2 = resample(X_train_nogdp, Y_train, n_samples=sample_size[1], random_state=random_state_seed, stratify=Y_train)\n",
    "X_train_nogdp_samp3, Y_train_nogdp_samp3 = resample(X_train_nogdp, Y_train, n_samples=sample_size[2], random_state=random_state_seed, stratify=Y_train)\n",
    "\n",
    "\n",
    "#Création des jeux d'entrainement (X_train) et de validation (Y_train) avec PIB : scenario 3\n",
    "merge_gdp = True\n",
    "\n",
    "X_train_gdp_samp1, Y_train_gdp_samp1 = resample(X_train_gdp, Y_train, n_samples=sample_size[0], random_state=random_state_seed, stratify=Y_train)\n",
    "X_train_gdp_samp2, Y_train_gdp_samp2 = resample(X_train_gdp, Y_train, n_samples=sample_size[1], random_state=random_state_seed, stratify=Y_train)\n",
    "X_train_gdp_samp3, Y_train_gdp_samp3 = resample(X_train_gdp, Y_train, n_samples=sample_size[2], random_state=random_state_seed, stratify=Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2.1.3 - Entraînement et évaluation par validation croisée<a name=\"TrainEval\"></a>\n",
    "\n",
    "La première étape consiste à initialiser les arbres de décision, pour ensuite introduire les données de chacun via la méthode _fit_. Comme décrit à la section [2.1.2](#sampling), des arbres sont créés pour chacun des scénarios, soit l'ensemble d'entraînement complet (8000 observations) et des échantillons de 1000, 2000 et 4000 instances. \n",
    "\n",
    "Chacun des scénarios est exploré avec et sans jointure du PIB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Définition du classeur. \n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Évaluation croisée\n",
    "\n",
    "L'évaluation croisée des résultats étant nécessaire pour chacun des arbres créés à l'étape précédente, celle-ci est présentée sous forme de fonction.\n",
    "\n",
    "Cette fonction repose principalement sur la méthode _cross_val_score_ permettant de retourner les métriques de précision, rappel et f1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cvs_wrapper(model, X_data, Y_data, value_count, scenario):\n",
    "\n",
    "    kfold = [3,10]\n",
    "\n",
    "    for fold in kfold:\n",
    "\n",
    "        scores =[]\n",
    "        scores = cross_val_score(model, X_data, Y_data, cv=fold, scoring=\"precision\")\n",
    "        scores_recall = cross_val_score(model, X_data, Y_data, cv=fold, scoring=\"recall\")\n",
    "        scores_f1 = cross_val_score(model, X_data,Y_data,cv=fold, scoring=\"f1\")\n",
    "        scores_accuracy = cross_val_score(model, X_data,Y_data,cv=fold, scoring=\"accuracy\")\n",
    "\n",
    "        scores = pd.DataFrame(scores, columns=['precision'])\n",
    "        scores['recall'] = scores_recall\n",
    "        scores['F1'] = scores_f1\n",
    "        scores['accuracy']=scores_accuracy\n",
    "\n",
    "        print(\"Scores de validation croisée pour un échantillon de\", value_count, \"instances,\", fold, \"plis (folds), sur des données\", scenario, \":\")\n",
    "        print(scores.sort_values(by=['F1'], ascending=False))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction créée, elle est appelée pour chacune des échantillons de données. Les résultats sont affichés dans les tableaux-ci dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée pour un échantillon de 2000 instances, 3 plis (folds), sur des données scenario1 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.523636  0.540230  0.527103  0.629129\n",
      "0   0.521898  0.553435  0.527103  0.626687\n",
      "1   0.494624  0.490421  0.496296  0.601199\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 2000 instances, 10 plis (folds), sur des données scenario1 :\n",
      "   precision    recall        F1  accuracy\n",
      "0   0.582278  0.620253  0.587500     0.685\n",
      "4   0.534884  0.576923  0.580247     0.650\n",
      "3   0.560000  0.518987  0.565789     0.660\n",
      "9   0.571429  0.538462  0.563758     0.650\n",
      "1   0.532609  0.607595  0.559524     0.635\n",
      "8   0.577465  0.500000  0.529801     0.665\n",
      "6   0.477778  0.576923  0.523256     0.575\n",
      "5   0.525641  0.500000  0.516129     0.625\n",
      "2   0.475610  0.518987  0.496894     0.575\n",
      "7   0.440000  0.487179  0.438710     0.575\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 4000 instances, 3 plis (folds), sur des données scenario1 :\n",
      "   precision    recall        F1  accuracy\n",
      "1   0.584178  0.562141  0.574976  0.663166\n",
      "2   0.543860  0.521073  0.536538  0.642161\n",
      "0   0.558824  0.537285  0.534500  0.653673\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 4000 instances, 10 plis (folds), sur des données scenario1 :\n",
      "   precision    recall        F1  accuracy\n",
      "3   0.673203  0.656051  0.662379    0.7350\n",
      "4   0.613497  0.643312  0.629283    0.7050\n",
      "2   0.593220  0.675159  0.625767    0.6875\n",
      "9   0.544944  0.628205  0.611621    0.6800\n",
      "1   0.627586  0.624204  0.610932    0.7000\n",
      "5   0.579268  0.630573  0.606811    0.6825\n",
      "0   0.638298  0.585987  0.599327    0.7150\n",
      "7   0.582353  0.592357  0.584337    0.6675\n",
      "6   0.605263  0.598726  0.583333    0.6800\n",
      "8   0.562914  0.589744  0.556634    0.6500\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 8000 instances, 3 plis (folds), sur des données scenario1 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.679487  0.711005  0.690141  0.756564\n",
      "1   0.682635  0.652632  0.668627  0.737158\n",
      "0   0.666012  0.641148  0.656863  0.734158\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 8000 instances, 10 plis (folds), sur des données scenario1 :\n",
      "   precision    recall        F1  accuracy\n",
      "7   0.746914  0.785942  0.769716   0.80250\n",
      "8   0.750799  0.757188  0.761290   0.81500\n",
      "9   0.776699  0.769968  0.758730   0.81000\n",
      "0   0.740061  0.770701  0.758190   0.81375\n",
      "4   0.750789  0.742038  0.751975   0.80875\n",
      "1   0.767442  0.729299  0.750000   0.80750\n",
      "3   0.707692  0.732484  0.720379   0.77750\n",
      "2   0.726667  0.671975  0.710098   0.78125\n",
      "5   0.707006  0.715655  0.708464   0.77750\n",
      "6   0.708609  0.680511  0.681892   0.76125\n",
      "\n",
      "\n",
      "\n",
      "Performance des modèles scenario2****************************************\n",
      "Scores de validation croisée pour un échantillon de 2000 instances, 3 plis (folds), sur des données scenario2 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.540741  0.532567  0.529630  0.630631\n",
      "0   0.515038  0.530534  0.517958  0.614693\n",
      "1   0.500000  0.513410  0.492481  0.604198\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 2000 instances, 10 plis (folds), sur des données scenario2 :\n",
      "   precision    recall        F1  accuracy\n",
      "0   0.595238  0.594937  0.600000     0.670\n",
      "4   0.541176  0.576923  0.564417     0.620\n",
      "3   0.585714  0.556962  0.563758     0.660\n",
      "9   0.565789  0.487179  0.557823     0.670\n",
      "1   0.522222  0.607595  0.539877     0.645\n",
      "8   0.547945  0.512821  0.530612     0.640\n",
      "2   0.456790  0.468354  0.530120     0.590\n",
      "6   0.467391  0.576923  0.511905     0.585\n",
      "5   0.519481  0.500000  0.490323     0.620\n",
      "7   0.486486  0.461538  0.461538     0.575\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 4000 instances, 3 plis (folds), sur des données scenario2 :\n",
      "   precision    recall        F1  accuracy\n",
      "1   0.567460  0.535373  0.575000  0.665416\n",
      "0   0.551308  0.535373  0.554054  0.644678\n",
      "2   0.537109  0.534483  0.532305  0.642161\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 4000 instances, 10 plis (folds), sur des données scenario2 :\n",
      "   precision    recall        F1  accuracy\n",
      "3   0.654321  0.656051  0.655949    0.7400\n",
      "4   0.602410  0.643312  0.631250    0.7075\n",
      "9   0.568966  0.641026  0.616314    0.6750\n",
      "2   0.589595  0.656051  0.615385    0.6900\n",
      "5   0.600000  0.611465  0.612121    0.6850\n",
      "1   0.633333  0.585987  0.603279    0.6950\n",
      "7   0.558824  0.605096  0.601881    0.6625\n",
      "0   0.656716  0.547771  0.599327    0.7000\n",
      "6   0.603896  0.585987  0.590476    0.6825\n",
      "8   0.559211  0.570513  0.564103    0.6450\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 8000 instances, 3 plis (folds), sur des données scenario2 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.681106  0.698565  0.696587  0.757689\n",
      "1   0.680485  0.650718  0.663725  0.740532\n",
      "0   0.669000  0.636364  0.654634  0.730409\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 8000 instances, 10 plis (folds), sur des données scenario2 :\n",
      "   precision    recall        F1  accuracy\n",
      "7   0.744615  0.769968  0.769716   0.80875\n",
      "9   0.746875  0.766773  0.764613   0.80625\n",
      "8   0.758730  0.747604  0.755556   0.81000\n",
      "0   0.747692  0.777070  0.753532   0.81250\n",
      "4   0.757098  0.754777  0.747218   0.81000\n",
      "1   0.758278  0.729299  0.739771   0.81000\n",
      "3   0.709480  0.735669  0.727838   0.78000\n",
      "5   0.703125  0.718850  0.711111   0.76500\n",
      "2   0.725753  0.687898  0.700658   0.77375\n",
      "6   0.709459  0.674121  0.693811   0.76375\n",
      "\n",
      "\n",
      "\n",
      "Performance des modèles scenario3****************************************\n",
      "Scores de validation croisée pour un échantillon de 2000 instances, 3 plis (folds), sur des données scenario3 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.529412  0.551724  0.533081  0.630631\n",
      "0   0.516605  0.526718  0.526515  0.623688\n",
      "1   0.477778  0.498084  0.468571  0.605697\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 2000 instances, 10 plis (folds), sur des données scenario3 :\n",
      "   precision    recall        F1  accuracy\n",
      "4   0.559524  0.576923  0.581818     0.635\n",
      "0   0.552941  0.569620  0.575000     0.685\n",
      "3   0.585714  0.544304  0.560000     0.665\n",
      "1   0.528736  0.569620  0.556213     0.620\n",
      "6   0.457447  0.551282  0.534884     0.580\n",
      "9   0.554054  0.512821  0.529032     0.645\n",
      "8   0.579710  0.487179  0.522876     0.640\n",
      "2   0.493827  0.506329  0.509317     0.590\n",
      "5   0.535211  0.525641  0.493506     0.610\n",
      "7   0.448718  0.448718  0.418919     0.605\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 4000 instances, 3 plis (folds), sur des données scenario3 :\n",
      "   precision    recall        F1  accuracy\n",
      "1   0.587649  0.550669  0.561841  0.658665\n",
      "0   0.550696  0.543021  0.545809  0.649175\n",
      "2   0.533074  0.532567  0.541586  0.652663\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 4000 instances, 10 plis (folds), sur des données scenario3 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.591954  0.630573  0.652568    0.6825\n",
      "3   0.660131  0.636943  0.645367    0.7425\n",
      "4   0.618182  0.649682  0.626959    0.7050\n",
      "5   0.597561  0.624204  0.613003    0.6950\n",
      "1   0.618421  0.611465  0.610932    0.7000\n",
      "0   0.640845  0.560510  0.604027    0.7025\n",
      "7   0.568047  0.617834  0.592593    0.6650\n",
      "9   0.568182  0.653846  0.592145    0.6775\n",
      "6   0.601307  0.592357  0.587859    0.6850\n",
      "8   0.568627  0.596154  0.565079    0.6400\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 8000 instances, 3 plis (folds), sur des données scenario3 :\n",
      "   precision    recall        F1  accuracy\n",
      "2   0.677036  0.705263  0.692235  0.760690\n",
      "1   0.685509  0.645933  0.660451  0.737533\n",
      "0   0.668663  0.637321  0.645477  0.727409\n",
      "\n",
      "\n",
      "Scores de validation croisée pour un échantillon de 8000 instances, 10 plis (folds), sur des données scenario3 :\n",
      "   precision    recall        F1  accuracy\n",
      "7   0.761755  0.779553  0.765354   0.80500\n",
      "8   0.748428  0.741214  0.765079   0.81375\n",
      "0   0.739938  0.786624  0.762951   0.80875\n",
      "9   0.746875  0.766773  0.755556   0.80625\n",
      "1   0.762987  0.719745  0.749591   0.80000\n",
      "4   0.751592  0.748408  0.744849   0.80250\n",
      "3   0.706422  0.742038  0.723270   0.77625\n",
      "5   0.703125  0.725240  0.711811   0.77000\n",
      "2   0.720930  0.697452  0.697218   0.77375\n",
      "6   0.698675  0.670927  0.693944   0.76375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#scenario #1\n",
    "cvs_wrapper(clf, X_train_nopop_samp1, Y_train_nopop_samp1, sample_size[0], \"scenario1\")\n",
    "cvs_wrapper(clf, X_train_nopop_samp2, Y_train_nopop_samp2, sample_size[1], \"scenario1\")\n",
    "cvs_wrapper(clf, X_train_nopop_samp3, Y_train_nopop_samp3, sample_size[2], \"scenario1\")\n",
    "\n",
    "\n",
    "#scenario #2\n",
    "print(\"\\nPerformance des modèles scenario2****************************************\")\n",
    "cvs_wrapper(clf, X_train_nogdp_samp1, Y_train_nogdp_samp1, sample_size[0], \"scenario2\")\n",
    "cvs_wrapper(clf, X_train_nogdp_samp2, Y_train_nogdp_samp2, sample_size[1], \"scenario2\")\n",
    "cvs_wrapper(clf, X_train_nogdp_samp3, Y_train_nogdp_samp3, sample_size[2], \"scenario2\")\n",
    "\n",
    "#scenario #3\n",
    "print(\"\\nPerformance des modèles scenario3****************************************\")\n",
    "cvs_wrapper(clf, X_train_gdp_samp1, Y_train_gdp_samp1, sample_size[0], \"scenario3\")\n",
    "cvs_wrapper(clf, X_train_gdp_samp2, Y_train_gdp_samp2, sample_size[1], \"scenario3\")\n",
    "cvs_wrapper(clf, X_train_gdp_samp3, Y_train_gdp_samp3, sample_size[2], \"scenario3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats\n",
    "\n",
    "Nous constatons donc que le meilleur résultat provient du modèle analysé selon les paramètres: \n",
    "\n",
    "* Échantillon de 8000 instances\n",
    "* 10 plis (folds)\n",
    "* Données sans pop et pip\n",
    "\n",
    "Les résultats sont: \n",
    "* precision: 0.75\n",
    "* recall: 0.79 \n",
    "* F1: 0.77\n",
    "* accuracy : 0.82\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2.1.5 - Optimisation des hyper-paramètres avec GridSearch<a name=\"gridsearch\"></a>\n",
    "\n",
    "Cette fonction tire profit de la méthode _GridSearchCV_ afin d'estimer les meilleurs paramètres pour l'ensemble de données sélectionné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folds = 3\n",
    "params_grid = {'max_depth': list(range(1,20)), 'min_samples_split': [10, 15, 20, 25]}\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "def grid_search_wrapper(splits, x_train, y_train):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = splits)\n",
    "    gs = GridSearchCV(clf, params_grid, cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    gs.fit(x_train, y_train)\n",
    "    #results=pd.DataFrame(gs.cv_results_)\n",
    "    #print(results['mean_test_score'])\n",
    "    \n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous débutons le reglage du modele du scenario1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario1\n",
      "Meilleurs paramètres\n",
      "{'max_depth': 2, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_search_nopop = grid_search_wrapper(folds, X_train_nopop, Y_train)\n",
    "\n",
    "print(\"scenario1\")\n",
    "print('Meilleurs paramètres')\n",
    "print(grid_search_nopop.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous poursuivons le reglage du modele du scenario2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario2\n",
      "Meilleurs paramètres\n",
      "{'max_depth': 2, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_search_nogdp = grid_search_wrapper(folds, X_train_nogdp, Y_train)\n",
    "print(\"scenario2\")\n",
    "print('Meilleurs paramètres')\n",
    "print(grid_search_nogdp.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons le reglage du modele du scenario3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario3\n",
      "Meilleurs paramètres\n",
      "{'max_depth': 2, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_search_gdp = grid_search_wrapper(folds, X_train_gdp, Y_train)\n",
    "print(\"scenario3\")\n",
    "print('Meilleurs paramètres')\n",
    "print(grid_search_gdp.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.1.6 - Test du meilleur modèle<a name=\"testmodel\">\n",
    "    \n",
    "Les paramètres ayant été identifiés, nous évaluons les résultats sur l'ensemble de données de test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avec le scenario1\n",
      "\n",
      "Matrice de confusion pour Decision Tree Classifier pour le jeu de données test:\n",
      "     pred_neg  pred_pos\n",
      "neg      1242         7\n",
      "pos       749         2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.77      1249\n",
      "           1       0.22      0.00      0.01       751\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.42      0.50      0.39      2000\n",
      "weighted avg       0.47      0.62      0.48      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search_nopop.predict(X_test_nopop)\n",
    "print(\"test avec le scenario1\")\n",
    "print('\\nMatrice de confusion pour Decision Tree Classifier pour le jeu de données test:')\n",
    "print(pd.DataFrame(confusion_matrix(Y_test, y_pred),columns=['pred_neg', 'pred_pos'],index = ['neg', 'pos']))\n",
    "\n",
    "print(metrics.classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nous poursuivons avec le test avec le scenario2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avec le scenario2\n",
      "\n",
      "Matrice de confusion pour Decision Tree Classifier pour le jeu de données test:\n",
      "     pred_neg  pred_pos\n",
      "neg      1242         7\n",
      "pos       749         2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.77      1249\n",
      "           1       0.22      0.00      0.01       751\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.42      0.50      0.39      2000\n",
      "weighted avg       0.47      0.62      0.48      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test avec le scenario2\n",
    "print(\"test avec le scenario2\")\n",
    "y_pred = grid_search_nogdp.predict(X_test_nogdp)\n",
    "print('\\nMatrice de confusion pour Decision Tree Classifier pour le jeu de données test:')\n",
    "print(pd.DataFrame(confusion_matrix(Y_test, y_pred),columns=['pred_neg', 'pred_pos'],index = ['neg', 'pos']))\n",
    "\n",
    "print(metrics.classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idem avec scenario3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avec le scenario3\n",
      "\n",
      "Matrice de confusion pour Decision Tree Classifier pour le jeu de données test:\n",
      "     pred_neg  pred_pos\n",
      "neg      1242         7\n",
      "pos       749         2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.77      1249\n",
      "           1       0.22      0.00      0.01       751\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.42      0.50      0.39      2000\n",
      "weighted avg       0.47      0.62      0.48      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"test avec le scenario3\")\n",
    "\n",
    "print('\\nMatrice de confusion pour Decision Tree Classifier pour le jeu de données test:')\n",
    "print(pd.DataFrame(confusion_matrix(Y_test, y_pred),columns=['pred_neg', 'pred_pos'],index = ['neg', 'pos']))\n",
    "\n",
    "print(metrics.classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2.1.8 - Analyse et interprétation des résultats<a name=\"analysis\">\n",
    "    \n",
    "    \n",
    "Les différents scénarios d'échantillonnage ont permis d'établir que le modèle lors de la validation croisée les meilleures performances: \n",
    "    \n",
    "* Échantillon de 8000 instances\n",
    "* 10 plis (folds)\n",
    "* Donnés sans pop et pip\n",
    "* precision: 0.75\n",
    "* recall: 0.79 \n",
    "* F1: 0.77\n",
    "    \n",
    "L'exploration des hyperparamètres a permis d'estimer que la meilleure combinaison de paramètres était: \n",
    "    \n",
    "* _max\\_depth_: 2\n",
    "* _min\\_samples\\_split_: 10\n",
    "    \n",
    "La performance de l'exactitude (accuracy) obtenue avec les données de test est de l'ordre de 60% qui est inférieure à celle obtenue avec la validation croisée qui est de 82%. On peut dire que le modele surajuste les données. Une maniere de régler ce problele de sur-apprentissage est de tenter d'améliorer le modele en 1) recourir à l'ajout d'autres données, ajouter des données supplémentaires d'entrainement si disponibilité ou bien 2) régalage des hyperparametres. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 2.2 - Entraînement d’un classeur multi-classes<a name=\"multiclass\"></a>\n",
    "\n",
    "## 2.2.1 - Transformation multi-classe de la variable \"revenue\"<a name=\"transfoMulti\"></a>\n",
    "\n",
    "\n",
    "\n",
    "une dicrétisation basée sur les quartiles:\n",
    "* _revenu\\_bas_: les données plus petites ou égales au 1er quantile.\n",
    "* _revenu\\_moyen_: les données contenues dans le 2ième et le 3ième quartile.\n",
    "* _revenu\\_élevé_: les données plus grandes que le 3ième quartile.\n",
    "\n",
    "La fonction ci-dessous permet donc de modifier l'attribut de classification selon ce processus de discrétisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def multiclass_att(data: pd.DataFrame, att_name):\n",
    "\n",
    "    # Délimiter les quartiles\n",
    "    Q1 = data[att_name].quantile(0.25)\n",
    "    Q3 = data[att_name].quantile(0.75)\n",
    "\n",
    "    # vecteur de conditions\n",
    "    conditions = [\n",
    "        (data[att_name] < Q1),\n",
    "        (data[att_name] >= Q1) & (data[att_name] <= Q3),\n",
    "        (data[att_name] > Q3)]\n",
    "\n",
    "    # vecteur de valeurs\n",
    "    conditions_values = [\"revenus_bas\", \"revenus_moyens\", \"revenus_eleve\"]\n",
    "    \n",
    "    # remplacement des valeurs\n",
    "    data[att_name] = np.select(conditions, conditions_values)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modifications sont donc apportées à l'ensemble de données avin de modifier la classification et le diviser en ensemble d'entrainement et de validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes pour le jeu d'entrainement:\n",
      " revenue\n",
      "revenus_moyens    4014\n",
      "revenus_bas       1998\n",
      "revenus_eleve     1988\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution des classes pour le jeu de test:\n",
      " revenue\n",
      "revenus_moyens    1010\n",
      "revenus_bas        495\n",
      "revenus_eleve      495\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# discrétisation de la variable revenue en fonction des 3 catégories\n",
    "\n",
    "train_set_multi = multiclass_att(train_set.copy(), \"revenue\")\n",
    "print(\"Distribution des classes pour le jeu d'entrainement:\\n\",train_set_multi[\"revenue\"].value_counts(ascending=False))\n",
    "\n",
    "test_set_multi = multiclass_att(test_set.copy(), \"revenue\")\n",
    "print(\"\\nDistribution des classes pour le jeu de test:\\n\", test_set_multi[\"revenue\"].value_counts(ascending=False))\n",
    "\n",
    "### Retrait de la variable revenue de l'ensemble d'entrainement\n",
    "X_train_multi = train_set_multi.drop(['revenue'], axis=1)\n",
    "Y_train_multi = train_set_multi['revenue']\n",
    "\n",
    "### Retrait de la variable revenue de l'ensemble de test\n",
    "X_test_multi = test_set_multi.drop(['revenue'],axis =1)\n",
    "Y_test_multi = test_set_multi['revenue']\n",
    "\n",
    "### Application du pipeline aux deux ensemble de données\n",
    "X_train_multi = full_pipeline.fit_transform(X_train_multi)\n",
    "X_test_multi = full_pipeline.fit_transform(X_test_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée du multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance du modèle de classification multi-classe:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   revenus_bas       0.25      0.27      0.26      1998\n",
      " revenus_eleve       0.23      0.24      0.23      1988\n",
      "revenus_moyens       0.49      0.47      0.48      4014\n",
      "\n",
      "      accuracy                           0.36      8000\n",
      "     macro avg       0.32      0.32      0.32      8000\n",
      "  weighted avg       0.37      0.36      0.36      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_multi = DecisionTreeClassifier(criterion=\"entropy\") \n",
    "\n",
    "cross_val_score(clf_multi, X_train_multi, Y_train_multi, cv=3, scoring=\"accuracy\")\n",
    "y_pred_multi = cross_val_predict(clf_multi, X_train_multi, Y_train_multi)\n",
    "\n",
    "\n",
    "labels = [\"revenus_bas\", \"revenus_eleve\", \"revenus_moyens\"]\n",
    "\n",
    "print(\"\\nPerformance du modèle de classification multi-classe:\")\n",
    "print(classification_report(Y_train_multi, y_pred_multi, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2.2.2 - Meilleur classeur pour discriminer les classes<a name=\"ClassMulti\"></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "\n",
      "Meilleur estimateur:  DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=20)\n",
      "\n",
      "Matrice de confusion pour le classeur multi-clases:\n",
      "[[   3    0  492]\n",
      " [   2    0  493]\n",
      " [   3    0 1007]]\n",
      "\n",
      "Performance du modèle de classification multi-classe:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   revenus_bas       0.38      0.01      0.01       495\n",
      " revenus_eleve       0.00      0.00      0.00       495\n",
      "revenus_moyens       0.51      1.00      0.67      1010\n",
      "\n",
      "      accuracy                           0.51      2000\n",
      "     macro avg       0.29      0.33      0.23      2000\n",
      "  weighted avg       0.35      0.51      0.34      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/abouzoua/Desktop/enseignement/8INF867/v8inf867/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "### Grid search afin d'identifier les meilleurs paramètres\n",
    "params = {'max_depth': list(range(2, 20)), 'min_samples_split': [10, 15, 20]}\n",
    "\n",
    "gs_multi = GridSearchCV(DecisionTreeClassifier(criterion=\"entropy\"), params, n_jobs=-1, cv=10, verbose=1)\n",
    "gs_multi.fit(X_train_multi, Y_train_multi)\n",
    "\n",
    "#le meilleur estimateur (modele) trouvé est:\n",
    "print(\"\\nMeilleur estimateur: \", gs_multi.best_estimator_)\n",
    "\n",
    "### test du meilleur modele obtenus:\n",
    "y_pred_multi = gs_multi.predict(X_test_multi)\n",
    "\n",
    "### Évaluation des mesures de performance:\n",
    "\n",
    "print(\"\\nMatrice de confusion pour le classeur multi-clases:\")\n",
    "print(metrics.confusion_matrix(Y_test_multi,y_pred_multi))\n",
    "\n",
    "labels = [\"revenus_bas\", \"revenus_eleve\", \"revenus_moyens\"]\n",
    "\n",
    "print(\"\\nPerformance du modèle de classification multi-classe:\")\n",
    "print(classification_report(Y_test_multi, y_pred_multi, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2.2.3 - Comparaison des résultats avec le classeur binaire<a name=\"compBinMulti\"></a>\n",
    "\n",
    "Le tableau ci-dessous présente les différents résultats en fonctions des types de classeurs et des jeux de données (_train_ et _test_): \n",
    "\n",
    "| Paramètre           | Binaire     | Multi-classe |\n",
    "|     :----:          |:----:       |:----:        |\n",
    "|_max\\_depth_         | 19          |4             |\n",
    "|_min\\_samples\\_split_| 10          |10            |\n",
    "||||||\n",
    "| Accuracy - Train     |0.82    |0.36|\n",
    "| Accuracy - Test    |0.60    |0.50|\n",
    "\n",
    "Nous constatons que le modèle de classification binaire est plus acceptable mais il surajuste le jeu de données. Le niveau de précision de l'autre modele étant faible et sous-ajuste les données.  nous pourrions considérer: \n",
    "* Explorer davantage d'hyper-paramètres via la méthode _GridSearchCV_. Bien que ces paramètres pourraient améliorer les performances, il est peu probable qu'ils aient un impact significatif. \n",
    "* Explorer une classification selon laquelle le nombre de classes demeure le même, mais dont la distribution des données parmi celles-ci est mieux balancée, permettant d'éviter certains de biais d'entraînement liés aux nombres de données par classes.\n",
    "* Revesiter certains variables comme country,\n",
    "* Explorer d'autres techniques...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
